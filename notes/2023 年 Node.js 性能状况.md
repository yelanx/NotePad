> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [blog.rafaelgss.dev](https://blog.rafaelgss.dev/state-of-nodejs-performance-2023)

> 专注于应用程序性能和软件架构的技术博客。前端只是 JSON ......

今年是 2023 年，[我们发布了 Node.js v20](https://nodejs.org/en/blog/release/v20.0.0)。这是一项重大成就，本文旨在使用科学数字来评估 Node.js 的性能状态。

所有基准测试结果都包含可重现的示例和硬件详细信息。为了减少普通读者的噪音，可重现的步骤将折叠在所有部分的开头。

本文旨在对不同版本的 Node.js 进行对比分析。它突出了改进和挫折，并提供了对这些变化背后原因的见解，但没有与其他 JavaScript 运行时进行任何比较。

为了进行这个实验，我们使用了 Node.js 版本**16.20.0**、**18.16.0**和**20.0.0**，并将基准套件分为三个不同的组：

1.  Node.js 内部基准

鉴于 Node.js 基准测试套件的巨大规模和耗时特性，我有选择地选择了在我看来对 Node.js 开发人员和配置影响更大的基准测试，例如使用 .读取 16 MB 的文件`fs.readfile`。这些基准测试按模块分组，例如`fs`和`streams`。有关 Node.js 基准测试套件的更多详细信息，请参阅 [Node.js 源代码](https://github.com/nodejs/node/tree/main/benchmark)。

2.  [nodejs-bench-操作](https://github.com/RafaelGSS/nodejs-bench-operations/)

我维护一个名为的存储库[`nodejs-bench-operations`](https://github.com/RafaelGSS/nodejs-bench-operations)，其中包括所有 Node.js 主要版本的基准操作，以及每个版本系列的最后三个版本。这样可以轻松比较不同版本之间的结果，例如 Node.js v16.20.0 和 v18.16.0，或 v19.8.0 和 v19.9.0，目的是识别 Node.js 代码库中的回归。如果您对 Node.js 比较感兴趣，关注此存储库可能会有所帮助（如果您觉得有帮助，请不要忘记给它一个星）。

3.  HTTP 服务器（框架）

这个实用的 HTTP 基准测试向各种路由发送大量请求，返回 JSON、纯文本和错误，以`express`和`fastify`作为参考。[主要目的是确定从 Node.js 内部基准测试和nodejs-bench-operations](https://github.com/RafaelGSS/nodejs-bench-operations)获得的结果是否适用于常见的 HTTP 应用程序。

> 💡 更新：由于本文涵盖的内容广泛，第三步也是最后一步将在后续文章中分享。[要保持更新和接收通知，我鼓励您在Twitter](https://twitter.com/_rafaelgss) / [LinkedIn](https://www.linkedin.com/in/rafaelgss/)上关注我 。

环境
--

为执行此基准测试，[AWS 专用主机](https://aws.amazon.com/ec2/dedicated-hosts/)与以下计算优化实例一起使用：

*   c6i.xlarge (Ice Lake) 3.5 GHz - 计算优化
*   4 个 vCPU
*   8 GB 内存
*   Canonical、Ubuntu、22.04 LTS、amd64 果酱
*   1GiB SSD 卷类型

Node.js 内部基准
------------

在此基准测试中选择了以下模块/命名空间：

*   `fs`- Node.js 文件系统
*   `events`- Node.js 事件类`EventEmitter`/`EventTarget`
*   `http`- Node.js HTTP 服务器 + 解析器
*   `misc`- Node.js 启动时间使用`child_processes`和`worker_threads`+`trace_events`
*   `module`- 节点.js`module.require`
*   `streams`- Node.js 流创建、销毁、可读等
*   `url`- Node.js URL 解析器
*   `buffers`- Node.js 缓冲区操作
*   `util`- Node.js 文本编码器/解码器

使用的配置可在 [RafaelGSS/node#state-of-nodejs](https://github.com/RafaelGSS/node/tree/state-of-nodejs)获得，所有结果都发布在主存储库中： [State of Node.js Performance 2023](https://github.com/RafaelGSS/state-of-nodejs-performance-2023)。

### Node.js 基准测试方法

在展示结果之前，解释用于确定基准结果置信度的统计方法至关重要。这个方法在之前的一篇博文中有详细的解释，你可以参考这里： **[准备和评估基准](https://blog.rafaelgss.dev/preparing-and-evaluating-benchmarks)**。

为了比较新 Node.js 版本的影响，我们在每个配置和 Node.js 16、18 和 20 上多次运行每个基准测试 (30)。当输出显示为表格时，有两列需要特别注意：

1.  _改进_-相对于新版本的改进 **百分比**
2.  _信心_- 告诉我们是否有足够的统计证据来验证_改进_

例如，考虑下表结果：

有 0.1% 的风险`fs.readfile`没有从 Node.js 16 提升到 Node.js 18（置信度 ***）。因此，我们对结果非常有信心。表结构可以理解为：

*   `fs/readfile.js`- 基准文件
*   `concurrent=1 len=16777216 encoding='ascii' duration=5`- 基准选项。每个基准文件可以有很多选项，在本例中，它使用 **ASCII**作为编码方法 在**5秒内读取****1 个****16777216**字节的并发文件。

> _对于统计头脑，脚本执行[独立/未配对的 2 组 t 检验](https://en.wikipedia.org/wiki/Student%27s_t-test#Equal_or_unequal_sample_sizes%2C_unequal_variances_%28sX1_%3E_2sX2_or_sX2_%3E_2sX1%29)，零假设两个版本的性能相同。如果 p 值小于 ，则置信度字段将显示星号`0.05`。— [编写和运行基准](https://github.com/nodejs/node/blob/main/doc/contributing/writing-and-running-benchmarks.md#comparing-nodejs-versions)_

### 基准设置

1.  克隆 fork Node.js 仓库
2.  结帐`state-of-nodejs`分行
3.  创建 Node.js 16、18 和 20 二进制文件
4.  运行 [`benchmark.sh`](https://github.com/RafaelGSS/state-of-nodejs-performance-2023/blob/main/nodejs-internal-benchmark/benchmark.sh) 脚本

### 文件系统

`fs.readfile`将 Node.js 从 16 升级到 18 时，使用带有编码的 API 时观察到 67% 的改进，`ascii` 使用`utf-8`.

[![](https://res.cloudinary.com/rafaelgss/image/upload/v1684174137/blog/state-of-nodejs-performance-2023/Untitled_jc1wyf.png)](https://res.cloudinary.com/rafaelgss/image/upload/v1684174137/blog/state-of-nodejs-performance-2023/Untitled_jc1wyf.png)

基准测试结果表明，将 Node.js 从版本 16 升级到 18 时，使用编码的 API提高 了大约**67%** ，使用时提高了 大约**12% 。用于基准测试的文件是使用以下代码片段创建的：**`fs.readfile``ascii``utf-8`

但是，在 Node.js 20 of **27%**`fs.readfile`上使用with 时出现了回归。此回归已报告给 Node.js 性能团队，预计会得到修复。另一方面，、 和显示了从 Node.js 18 到 Node.js 20 的改进。Node.js 18 和 20 之间的比较可以在下面的基准测试结果中看到：`ascii``fs.opendir``fs.realpath``fs.readdir`

如果您使用的是 Node.js 16，则可以使用以下 Node.js 16 和 Node.js 20 之间的比较

[![](https://res.cloudinary.com/rafaelgss/image/upload/v1684174215/blog/state-of-nodejs-performance-2023/Untitled_l9yunq.png)](https://res.cloudinary.com/rafaelgss/image/upload/v1684174215/blog/state-of-nodejs-performance-2023/Untitled_l9yunq.png)

### 事件

该`EventTarget`班级在活动方面表现出最显着的进步。该基准涉及使用`EventTarget.prototype.dispatchEvent(new Event('foo'))`.

Upgrading from Node.js 16 to Node.js 18 can deliver an improvement of nearly **15%** in event dispatching performance. But the real jump comes when upgrading from Node.js 18 to Node.js 20, which can yield a performance improvement of up to **200%** when there is only a single listener.

[![](https://res.cloudinary.com/rafaelgss/image/upload/v1684174293/blog/state-of-nodejs-performance-2023/Untitled_dnvmk0.png)](https://res.cloudinary.com/rafaelgss/image/upload/v1684174293/blog/state-of-nodejs-performance-2023/Untitled_dnvmk0.png)

The `EventTarget` class is a crucial component of the Web API and is utilized in various parent features such as `AbortSignal` and `worker_threads`. As a result, optimizations made to this class can potentially impact the performance of these features, including `fetch` and `AbortController`. Additionally, the `EventEmitter.prototype.emit` API also saw a notable improvement of approximately **11.5%** when comparing Node.js 16 to Node.js 20. A comprehensive comparison is provided below for your reference:

### HTTP

The HTTP Servers are one of the most impactful layers of improvement in Node.js. It isn’t a myth that most Node.js applications nowadays run an HTTP Server. So, any change can be easily considered a _semver-major_ and increase the efforts for a compatible improvement in performance.

Therefore, the HTTP server utilized is an `http.Server` that replies 4 chunks of 256 bytes each containing ‘C’ on each request, as you can see in this example:

When comparing the performance of Node.js 16 and Node.js 18, there is a noticeable 8% improvement. However, upgrading from Node.js 18 to Node.js 20 resulted in a significant improvement of **96.13%**.

[![](https://res.cloudinary.com/rafaelgss/image/upload/v1684174353/blog/state-of-nodejs-performance-2023/Untitled_rjsskx.png)](https://res.cloudinary.com/rafaelgss/image/upload/v1684174353/blog/state-of-nodejs-performance-2023/Untitled_rjsskx.png)

These benchmark results were collected using [`test-double-http`](https://github.com/nodejs/node/blob/main/benchmark/_test-double-benchmarker.js) benchmarker method. Which is, a simple Node.js script to send HTTP GET requests:

By switching to more reliable benchmarking tools such as `autocannon` or `wrk`, we observed a significant drop in the reported improvement — from **96%** to **9%**. [This indicates that the previous benchmarking method had limitations or errors](https://github.com/nodejs/performance/issues/80). However, the actual performance of the HTTP server has improved, and we need to carefully evaluate the percentage of improvement with the new benchmarking approach to accurately assess the progress made.

**Should I expect a 96%/9% performance improvement in my Express/Fastify application?**

Absolutely, not. Frameworks may opt not to use the internal HTTP API — that’s one of the reasons Fastify is… fast! For this reason, another benchmark suite was considered in this report (3. HTTP Servers).

### Misc

According to our tests, the `startup.js` script has demonstrated a significant improvement in the Node.js process lifecycle, with a 27% boost observed from Node.js version 18 to version 20. This improvement is even more impressive when compared to Node.js version 16, where the startup time was reduced by 34.75%!

As modern applications increasingly rely on serverless systems, reducing startup time has become a crucial factor in improving overall performance. It’s worth noting that the Node.js team is always working towards optimizing this aspect of the platform, as evidenced by our strategic initiative: [https://github.com/nodejs/node/issues/35711](https://github.com/nodejs/node/issues/35711).

These improvements in startup time not only benefit serverless applications but also enhance the performance of other Node.js applications that rely on quick boot-up times. Overall, these updates demonstrate the Node.js team’s commitment to enhancing the platform’s speed and efficiency for all users.

This benchmark is pretty straightforward. We measure the time elapsed when creating a new [mode] using the given [script] where [mode] can be:

*   `process` - a new Node.js process
*   `worker` - a Node.js worker_thread

And [script] is divided into:

*   `benchmark/fixtures/require-builtins` - a script that requires all the Node.js modules
*   `test/fixtures/semicolon` - an empty script — containing a single `;` (semicolon)

This experiment can be easily reproducible with [`hyperfine`](https://github.com/sharkdp/hyperfine) or `time`:

> 💡 The warmup is necessary to consider the influence of the file system cache

The `trace_events` module has also undergone a notable performance boost, with a **7%** improvement observed when comparing Node.js version 16 to version 20. It’s worth noting that this improvement was slightly lower, at **2.39%**, when comparing Node.js version 18 to version 20.

### Module

`require()` (or `module.require`) has long been a culprit of slow Node.js startup times. However, recent performance improvements suggest that this function has been optimized as well. Between Node.js versions 18 and 20, we observed improvements of **4.20%** when requiring `.js` files, **6.58%** for `.json` files, and **9.50%** when reading directories - all of which contribute to faster startup times.

Optimizing `require()` is crucial because it is a function that’s used heavily in Node.js applications. By reducing the time it takes for this function to execute, we can significantly speed up the entire startup process and improve the user experience.

[![](https://res.cloudinary.com/rafaelgss/image/upload/v1684174504/blog/state-of-nodejs-performance-2023/compare-module-18-20_nzhhvy.png)](https://res.cloudinary.com/rafaelgss/image/upload/v1684174504/blog/state-of-nodejs-performance-2023/compare-module-18-20_nzhhvy.png)

### Streams

Streams are an incredibly powerful and widely used feature of Node.js. However, between Node.js versions 16 and 18, some operations related to streams became slower. This includes creating and destroying `Duplex`, `Readable`, `Transform`, and `Writable` streams, as well as the `.pipe()` method for Readable → Writable streams.

The graph below illustrates this regression:

[![](https://res.cloudinary.com/rafaelgss/image/upload/v1684174544/blog/state-of-nodejs-performance-2023/compare-streams-16-18-streams-bar_zfseff.png)](https://res.cloudinary.com/rafaelgss/image/upload/v1684174544/blog/state-of-nodejs-performance-2023/compare-streams-16-18-streams-bar_zfseff.png)

However, this `pipe` regression was reduced in Node.js 20:

And as you may have noticed, some types of streams (`Transform` specifically) are regressed in Node.js 20. Therefore, Node.js 16 still has the fastest streams — for this specific benchmark, please do not read this benchmark result as ‘Node.js streams in v18 and v20 are so slow!’ This is a specific benchmark that may or may not affect your workload. For instance, if you look at a naive comparison [in the nodejs-bench-operations](https://github.com/RafaelGSS/nodejs-bench-operations/blob/main/RESULTS-v20.md#streamwritable), you will see that the following snippet performs better on Node.js 20 than its predecessors:

The fact is, the instantiation and destroy methods play an important role in the Node.js ecosystem. Hence, it’s very likely to have a negative impact on some libraries. However, this regression is [being monitored closely](https://github.com/nodejs/performance/issues/79) in the [Node.js Performance WG](https://github.com/nodejs/performance).

[![](https://res.cloudinary.com/rafaelgss/image/upload/v1684174569/blog/state-of-nodejs-performance-2023/compare-streams-16-20-streams-bar_xodyxx.png)](https://res.cloudinary.com/rafaelgss/image/upload/v1684174569/blog/state-of-nodejs-performance-2023/compare-streams-16-20-streams-bar_xodyxx.png)

Note that the readable async iterator becomes slightly faster (~6.14%) on Node.js 20.

### URL

Since Node.js 18, a new URL parser dependency was added to Node.js — [Ada](https://github.com/ada-url/ada). This addition bumped the Node.js performance when parsing URLs to a new level. Some results could reach up to an improvement of **400%**. As a regular user, you may not use it directly. But if you use an HTTP server then it’s very likely to be affected by this performance improvement.

The URL benchmark suite is pretty large. For this reason, only WHATWG URL benchmark results will be covered.

`url.parse()` and `url.resolve()` are both deprecated and legacy APIs. Even though its usage is considered a risk for any Node.js application, developers still use it. Quoting Node.js documentation:

> `url.parse()` uses a lenient, non-standard algorithm for parsing URL strings. It is prone to security issues such as [host name spoofing](https://hackerone.com/reports/678487) and incorrect handling of usernames and passwords. Do not use with untrusted input. CVEs are not issued for `url.parse()` vulnerabilities. Use the [WHATWG URL](https://nodejs.org/api/url.html#the-whatwg-url-api) API instead.

If you are curious about the performance changes of `url.parse` and `url.resolve`, check out the [State of Node.js Performance 2023 repository](https://github.com/RafaelGSS/state-of-nodejs-performance-2023#url-results).

That said, it’s really interesting to see the results of the new whatwg-url-parse:

[![](https://res.cloudinary.com/rafaelgss/image/upload/v1684174627/blog/state-of-nodejs-performance-2023/compare-url-16-20-whatwg-bar_wiaczh.png)](https://res.cloudinary.com/rafaelgss/image/upload/v1684174627/blog/state-of-nodejs-performance-2023/compare-url-16-20-whatwg-bar_wiaczh.png)

Below is a list of URLs used for benchmarking, which were selected based on the benchmark configuration

With the recent upgrade of Ada 2.0 in Node.js 20, it’s fair to say there’s also a significant improvement when comparing Node.js 18 to Node.js 20:

[![](https://res.cloudinary.com/rafaelgss/image/upload/v1684174655/blog/state-of-nodejs-performance-2023/compare-url-18-20-whatwg-bar_pocrnv.png)](https://res.cloudinary.com/rafaelgss/image/upload/v1684174655/blog/state-of-nodejs-performance-2023/compare-url-18-20-whatwg-bar_pocrnv.png)

And the benchmark file is pretty simple:

The only difference is the second parameter that is used as a base when creating/parsing the URL. It’s also worth mentioning that when a base is passed (_withBase=’true’_), it tends to perform faster than the regular usage (`new URL(data)`). See all the results expanded in [the main repository](https://github.com/RafaelGSS/state-of-nodejs-performance-2023#url-results).

### Buffers

In Node.js, buffers are used to handle binary data. Buffers are a built-in data structure that can be used to store raw binary data in memory, which can be useful when working with network protocols, file system operations, or other low-level operations. Overall, buffers are an important part of Node.js and are used extensively throughout the platform for handling binary data.

For those of you who make use directly or indirectly of Node.js buffers, I have good news (mainly for Node.js 20 early adopters).

Besides improving the performance of `Buffer.from()` Node.js 20 fixed two main regressions from Node.js 18:

*   `Buffer.concat()`

[![](https://res.cloudinary.com/rafaelgss/image/upload/v1684174695/blog/state-of-nodejs-performance-2023/compare-buffers-16-18-concat-bar_iymlbc.png)](https://res.cloudinary.com/rafaelgss/image/upload/v1684174695/blog/state-of-nodejs-performance-2023/compare-buffers-16-18-concat-bar_iymlbc.png)

Node.js version 20 has shown significant improvements compared to version 18, and these improvements remain apparent even when compared to version 16:

[![](https://res.cloudinary.com/rafaelgss/image/upload/v1684174708/blog/state-of-nodejs-performance-2023/compare-buffers-18-20-concat-bar_o2sqom.png)](https://res.cloudinary.com/rafaelgss/image/upload/v1684174708/blog/state-of-nodejs-performance-2023/compare-buffers-18-20-concat-bar_o2sqom.png)

[![](https://res.cloudinary.com/rafaelgss/image/upload/v1684174721/blog/state-of-nodejs-performance-2023/compare-buffers-16-20-concat-bar_yffmjf.png)](https://res.cloudinary.com/rafaelgss/image/upload/v1684174721/blog/state-of-nodejs-performance-2023/compare-buffers-16-20-concat-bar_yffmjf.png)

*   `Buffer.toJSON()`

From Node.js 16 to Node.js 18, a drop of **88%** in the performance of `Buffer.toJSON` was observed:

However, this regression was fixed and improved in Node.js 20 by orders of magnitude!

Therefore, it’s correct to state that Node.js 20 is the fastest version of Node.js in dealing with buffers.

See the full comparison between Node.js 20 and Node.js 18 below:

### Text Encoding and Decoding

TextDecoder and TextEncoder are two JavaScript classes that are part of the Web APIs specification and are available in modern web browsers and Node.js. Together, TextDecoder and TextEncoder provide a simple and efficient way to work with text data in JavaScript, allowing developers to perform various operations involving strings and character encodings.

Decoding and Encoding becomes considerably faster than in Node.js 18. With the addition of **[simdutf](https://github.com/simdutf/simdutf)** for UTF-8 parsing the observed benchmark, results improved by **364%** (an extremely impressive leap) when decoding in comparison to Node.js 16.

[![](https://res.cloudinary.com/rafaelgss/image/upload/v1684174777/blog/state-of-nodejs-performance-2023/compare-util-16-18-bar_eafprf.png)](https://res.cloudinary.com/rafaelgss/image/upload/v1684174777/blog/state-of-nodejs-performance-2023/compare-util-16-18-bar_eafprf.png)

Those improvements got even better on Node.js 20, with a performance improvement of **25%** in comparison to Node.js 18. See the full results in the [state-of-nodejs-performance-2023](https://github.com/RafaelGSS/state-of-nodejs-performance-2023#util) repository.

Performance improvements were also observed when comparing _encoding_ methods on Node.js 18. From Node.js 16 to Node.js 18, the `TextEncoder.encodeInto` reached **93.67%** of improvement in the current observation (using `ascii` with a string length of 256):

[![](https://res.cloudinary.com/rafaelgss/image/upload/v1684174830/blog/state-of-nodejs-performance-2023/compare-util-16-18-encode-bar_e0o0fy.png)](https://res.cloudinary.com/rafaelgss/image/upload/v1684174830/blog/state-of-nodejs-performance-2023/compare-util-16-18-encode-bar_e0o0fy.png)

Node.js Bench Operations
------------------------

The benchmarking operations in Node.js have always piqued my curiosity. As someone who enjoys exploring the intricacies of Node.js and its underlying technology, I find it fascinating to delve into the details of these operations, particularly those related to the V8 engine. In fact, I often like to share my findings with others through talks and workshops delivered by [NearForm](https://www.nearform.com/), a company I’m affiliated with. If you’re interested, you can find more information about my presentations on this topic by [clicking this link](https://rafaelgss.dev/).

In addition, these benchmarks will use the `ops/sec` metric, which basically means the number of operations that were performed in one second. It’s important to emphasize that this can only mean a very small fraction of your computing time. If you have read my previous article ([Preparing and Evaluating Benchmarks](https://blog.rafaelgss.dev/preparing-and-evaluating-benchmarks)) you should remember the ‘Evaluating Results’ section, where I approach the problem with `ops/sec` in real-world applications — if not, you should consider returning to it.

### Parsing Integers

Parsing strings to numbers can be accomplished using either **`+`** or `parseInt(x, 10)`. Previous benchmark results showed that using `+` was faster than `parseInt(x, 10)` in earlier versions of Node.js, as illustrated in the table below:

<table><thead><tr><th>name</th><th>ops/sec</th><th>samples</th></tr></thead><tbody><tr><td>Using parseInt(x, 10) - small number (2 len)</td><td>283,768,532</td><td>91</td></tr><tr><td>Using parseInt(x, 10) - big number (10 len)</td><td>21,307,115</td><td>100</td></tr><tr><td>Using + - small number (2 len)</td><td>849,906,952</td><td>100</td></tr><tr><td>Using + - big number (10 len)</td><td>849,173,336</td><td>97</td></tr></tbody></table>

[Source](https://github.com/RafaelGSS/nodejs-bench-operations/blob/main/RESULTS-v18.md#parsing-integer)

However, with the release of Node.js 20 and the new V8 version (11.4), both operations have become equivalent in terms of performance, as shown in the updated benchmark results below:

<table><thead><tr><th>name</th><th>ops/sec</th><th>samples</th></tr></thead><tbody><tr><td>Using parseInt(x, 10) - small number (2 len)</td><td>856,413,575</td><td>98</td></tr><tr><td>Using parseInt(x, 10) - big number (10 len)</td><td>856,754,259</td><td>96</td></tr><tr><td>Using + - small number (2 len)</td><td>857,364,191</td><td>98</td></tr><tr><td>Using + - big number (10 len)</td><td>857,511,971</td><td>96</td></tr></tbody></table>

[Source](https://github.com/RafaelGSS/nodejs-bench-operations/blob/main/RESULTS-v20.md#parsing-integer)

### Super vs This

One of the interesting benchmarks that have changed with the addition of Node.js 20 is the usage of `this` or `super` in classes, as you can see in the example underneath:

The comparison between `super` and `this` in Node.js 18 was producing the following operations per second (ops/sec):

<table><thead><tr><th>name</th><th>ops/sec</th><th>samples</th></tr></thead><tbody><tr><td>Using super</td><td>159,426,608</td><td>96</td></tr><tr><td>Using this</td><td>160,092,440</td><td>91</td></tr></tbody></table>

[Source](https://github.com/RafaelGSS/nodejs-bench-operations/blob/main/RESULTS-v18.md#super-vs-this)

There isn’t a significant difference between both approaches and on Node.js 20. This statement holds with a slight difference:

<table><thead><tr><th>name</th><th>ops/sec</th><th>samples</th></tr></thead><tbody><tr><td>Using super</td><td>850,760,436</td><td>97</td></tr><tr><td>Using this</td><td>853,619,840</td><td>99</td></tr></tbody></table>

[Source](https://github.com/RafaelGSS/nodejs-bench-operations/blob/main/RESULTS-v20.md#super-vs-this)

Based on the benchmark results, it appears that there has been a significant increase in performance when using `this` on Node.js 20 compared to Node.js 18. This increase is quite remarkable, with `this` achieving an impressive _853,619,840 ops/sec_ on Node.js 20 compared to only _160,092,440 ops/sec_ on Node.js 18, which is, **433%** better! Apparently, it has the same property access method as a regular object: `obj.property1`. Also, note that both operations were tested in the same dedicated environment. Therefore, it’s unlikely to have occurred by chance.

### Property Access

There are various ways to add properties to objects in JavaScript, each with its own purpose and sometimes ambiguous in nature. As a developer, you may wonder about the efficiency of property access in each of these methods.

The good news is that the nodejs-bench-operations repository includes a comparison of these methods, which sheds light on their performance characteristics. In fact, this benchmarking data reveals that the property access in Node.js 20 has seen significant improvements, particularly when using objects with `writable: true` and `enumerable/configurable: false` properties.

On Node.js 18 the property access (myObj.test) was producing _166,422,265 ops/sec_. However, under the same circumstances, Node.js 20 is producing _857,316,403 ops/sec_! This and other particularities around property access can be found in the following benchmark results:

*   Property getter access [v18](https://github.com/RafaelGSS/nodejs-bench-operations/blob/main/RESULTS-v18.md#property-getter-access) / [v20](https://github.com/RafaelGSS/nodejs-bench-operations/blob/main/RESULTS-v20.md#property-getter-access)
*   Property setter access [v18](https://github.com/RafaelGSS/nodejs-bench-operations/blob/main/RESULTS-v18.md#property-setter-access) / [v20](https://github.com/RafaelGSS/nodejs-bench-operations/blob/main/RESULTS-v20.md#property-setter-access)
*   Property access after shape transition [v18](https://github.com/RafaelGSS/nodejs-bench-operations/blob/main/RESULTS-v18.md) / [v20](https://github.com/RafaelGSS/nodejs-bench-operations/blob/main/RESULTS-v20.md#property-access-after-shape-transition)

### Array.prototype.at

`Array.prototype.at(-1)` is a method that was introduced in the ECMAScript 2021 specification. It allows you to access the last element of an array without knowing its length or using negative indices, which can be a useful feature in certain use cases. In this way, the `at()` method provides a more concise and readable way to access the last element of an array, compared to traditional methods like `array[array.length - 1]`.

On Node.js 18 this access was considerably slower in comparison to `Array[length-1]`:

<table><thead><tr><th>name</th><th>ops/sec</th><th>samples</th></tr></thead><tbody><tr><td>Length = 100 - Array.at</td><td>26,652,680</td><td>99</td></tr><tr><td>Length = 10_000 - Array.at</td><td>26,317,564</td><td>97</td></tr><tr><td>Length = 1_000_000 - Array.at</td><td>27,187,821</td><td>98</td></tr><tr><td>Length = 100 - Array[length - 1]</td><td>848,118,011</td><td>98</td></tr><tr><td>Length = 10_000 - Array[length - 1]</td><td>847,958,319</td><td>100</td></tr><tr><td>Length = 1_000_000 - Array[length - 1]</td><td>847,796,498</td><td>101</td></tr></tbody></table>

[Source](https://github.com/RafaelGSS/nodejs-bench-operations/blob/main/RESULTS-v18.md#get-the-last-item-of-an-array)

[Since Node.js 19](https://twitter.com/_rafaelgss/status/1619076762088120321), Array.prototype.at is equivalent to the old-fashioned Array[length-1] as the table below suggests:

<table><thead><tr><th>name</th><th>ops/sec</th><th>samples</th></tr></thead><tbody><tr><td>Length = 100 - Array.at</td><td>852,980,778</td><td>99</td></tr><tr><td>Length = 10_000 - Array.at</td><td>854,299,272</td><td>99</td></tr><tr><td>Length = 1_000_000 - Array.at</td><td>853,374,694</td><td>98</td></tr><tr><td>Length = 100 - Array[length - 1]</td><td>854,589,197</td><td>95</td></tr><tr><td>Length = 10_000 - Array[length - 1]</td><td>856,122,244</td><td>95</td></tr><tr><td>Length = 1_000_000 - Array[length - 1]</td><td>856,557,974</td><td>99</td></tr></tbody></table>

[Source](https://github.com/RafaelGSS/nodejs-bench-operations/blob/main/RESULTS-v20.md#get-the-last-item-of-an-array)

### String.prototype.includes

Most people know that _RegExp_ is very often the source of many bottlenecks in any kind of application. For instance, you might want to check if a certain variable contains `application/json`.And while you can do it in several manners, most of the time you will end up using either:

*   `/application\/json/.test(text)` - RegEx

or

*   `text.includes('application/json')` - String.prototype.includes

What some of you may not know is that `String.prototype.includes` is pretty much as slow as RegExp on Node.js 16.

<table><thead><tr><th>name</th><th>ops/sec</th><th>samples</th></tr></thead><tbody><tr><td>Using includes</td><td>16,056,204</td><td>97</td></tr><tr><td>Using indexof</td><td>850,710,330</td><td>100</td></tr><tr><td>Using RegExp.test</td><td>15,227,370</td><td>98</td></tr><tr><td>Using RegExp.text with cached regex pattern</td><td>15,808,350</td><td>97</td></tr><tr><td>Using new RegExp.test</td><td>4,945,475</td><td>98</td></tr><tr><td>Using new RegExp.test with cached regex pattern</td><td>5,944,679</td><td>100</td></tr></tbody></table>

[Source](https://github.com/RafaelGSS/nodejs-bench-operations/blob/main/RESULTS-v16.md#string-searching)

However, since Node.js 18 this behavior was _fixed_.

<table><thead><tr><th>name</th><th>ops/sec</th><th>samples</th></tr></thead><tbody><tr><td>Using includes</td><td>856,127,951</td><td>101</td></tr><tr><td>Using indexof</td><td>856,709,023</td><td>98</td></tr><tr><td>Using RegExp.test</td><td>16,623,756</td><td>98</td></tr><tr><td>Using RegExp.text with cached regex pattern</td><td>16,952,701</td><td>99</td></tr><tr><td>Using new RegExp.test</td><td>4,704,351</td><td>95</td></tr><tr><td>Using new RegExp.test with cached regex pattern</td><td>5,660,755</td><td>95</td></tr></tbody></table>

[Source](https://github.com/RafaelGSS/nodejs-bench-operations/blob/main/RESULTS-v18.md#string-searching)

### Crypto.verify

In Node.js, the crypto module provides a set of cryptographic functionalities that can be used for various purposes, such as creating and verifying digital signatures, encrypting and decrypting data, and generating secure random numbers. One of the methods available in this module is `crypto.verify()`, which is used to verify a digital signature generated by the `crypto.sign()` method.

Node.js 14 (End-of-Life) uses OpenSSL 1.x. On Node.js 16 we’ve had the addition of the [QUIC protocol](https://en.wikipedia.org/wiki/QUIC), but still using OpenSSL version 1. However, in Node.js 18 we’ve updated OpenSSL to version 3.x (over QUIC), and a [regression was found](https://github.com/nodejs/performance/issues/72) after Node.js 18 that reduced from 30k ops/sec to 6~7k ops/sec. [As I’ve mentioned in the tweet](https://twitter.com/_rafaelgss/status/1646498181675458560), it’s very likely to be caused by the new OpenSSL version. Again, our team is looking into it and if you have any insight on this, feel free to comment on the issue: [https://github.com/nodejs/performance/issues/72](https://github.com/nodejs/performance/issues/72).

Node.js performance initiatives
-------------------------------

The Node.js team has always been careful to ensure that its APIs and core functionalities are optimized for speed and resource usage.

In order to further enhance the performance of Node.js, the team has recently [introduced a new strategic initiative called ‘Performance’](https://github.com/nodejs/node/blob/HEAD/doc/contributing/strategic-initiatives.md), which is chaired by [Yagiz Nizipli](https://www.yagiz.co/). This initiative is aimed at identifying and addressing performance bottlenecks in the Node.js runtime and core modules, as well as improving the overall performance and scalability of the platform.

In addition to the Performance initiative, there are several other initiatives currently underway that are focused on optimizing different aspects of Node.js. One of these initiatives is the [‘Startup Snapshot’ initiative](https://github.com/nodejs/node/issues/35711), which is chaired by [Joyee](https://joyeecheung.github.io/blog/). This initiative is aimed at reducing the startup time of Node.js applications, which is a critical factor in improving the overall performance and user experience of web applications.

Therefore, if you are interested in this subject, consider joining the meetings every other week, and feel free to send a message in the `#nodejs-core-performance` channel on the [OpenJS Foundation Slack](https://openjs-foundation.slack.com/).

### Things to keep an eye on

Besides the strategic initiatives, there are some pull requests that are very likely to have a great impact on the Node.js performance — at the moment I’m writing the below post (it isn’t merged yet):

*   Node.js Errors - [https://github.com/nodejs/node/pull/46648](https://github.com/nodejs/node/pull/46648)

Errors are very expensive to create in Node.js. It’s very often a source of bottlenecks in Node.js applications. As an example, [I conducted research on the implementation of fetch in Node.js](https://github.com/nodejs/undici/issues/1203#issuecomment-1100969210) (undici) and discovered one of the villains in the Node.js WebStreams implementation is error creation. Hence, by optimizing error objects in Node.js, we can improve the overall efficiency of the platform and reduce the risk of bottlenecks.

*   Pointer compression builds - [https://github.com/nodejs/build/issues/3204](https://github.com/nodejs/build/issues/3204)

Pointer compression is a technique used in computer programming to reduce the memory usage of programs that make use of many pointers. While it doesn’t improve performance directly, it can indirectly improve performance by reducing cache misses and page faults. This certainly [can reduce some infra costs, as described in the issue thread](https://github.com/nodejs/TSC/issues/790#issuecomment-1427005737).

*   Increase default`--max-semi-space-size` - [https://github.com/nodejs/node/pull/47277](https://github.com/nodejs/node/pull/47277)

[An issue was created in March 2022](https://github.com/nodejs/node/issues/42511) suggesting increasing the V8 `max_semi_space_size` with the objective to reduce the Garbage Collection (Scavenge specifically) runs and increasing the overall throughput in the web tooling benchmark. We’re still evaluating its impact and it may or may not arrive in Node.js 21.

*   bump `highWaterMark` value on Node.js Readable/Writable streams - [https://github.com/nodejs/node/pull/46608](https://github.com/nodejs/node/pull/46608)

This PR increases the default value for `highWaterMark` value in Node.js streams. It’s expected to perceive a performance improvement in the Node.js stream usage with default options. This PR however, is a `semver-major` change and should arrive on Node.js 21. For a detailed benchmark result, wait for: ‘State of Node.js Performance 2023 - P2’ at the end of the year.

Conclusion
----------

Despite some regressions in the Node.js streams and crypto module, Node.js 20 boasts significant improvements in performance compared to previous versions. Notable enhancements have been observed in JavaScript operations such as property access, URL parsing, buffers/text encoding and decoding, startup/process lifecycle time, and EventTarget, among others.

The Node.js performance team ([nodejs/performance](https://github.com/nodejs/performance)) has expanded its scope, leading to greater contributions in optimizing performance with each new version. This trend indicates that Node.js will continue to become faster over time.

It’s worth mentioning that the benchmark tests focus on specific operations, which may or may not directly impact your specific use case. Therefore, I strongly recommend reviewing all the benchmark results in the [state-of-nodejs-performance repository](https://github.com/RafaelGSS/state-of-nodejs-performance-2023) and ensuring that these operations align with your business requirements.

Acknowledgments
---------------

I would like to express my sincere gratitude to all the reviewers who took the time to provide valuable feedback on my blog post. Thank you for your time, expertise, and constructive comments.

*   [Vinicius Lourenço](https://twitter.com/vinii_joga10)
*   [Yagiz Nizipli](https://twitter.com/yagiznizipli)
*   [Debadree Chatterjee](https://twitter.com/DebadreeC)
*   [Igor Savin](https://twitter.com/kibertoad)
*   [Paolo Insogna](https://twitter.com/p_insogna)

* * *