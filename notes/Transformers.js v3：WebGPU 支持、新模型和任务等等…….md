> æœ¬æ–‡ç”± [ç®€æ‚¦ SimpRead](http://ksria.com/simpread/) è½¬ç ï¼Œ åŸæ–‡åœ°å€ [huggingface.co](https://huggingface.co/blog/transformersjs-v3)

> æˆ‘ä»¬æ­£è‡´åŠ›äºé€šè¿‡å¼€æºå’Œå¼€æ”¾å¼ç§‘å­¦æ¨åŠ¨äººå·¥æ™ºèƒ½çš„å‘å±•å¹¶ä½¿å…¶æ°‘ä¸»åŒ–......

[è¿”å›æ–‡ç« ](/blog)

[](#transformersjs-v3-webgpu-support-new-models--tasks-and-more)Transformers.js v3ï¼šWebGPU æ”¯æŒã€æ–°æ¨¡å‹å’Œä»»åŠ¡ç­‰ç­‰â€¦â€¦
=======================================================================================================

2024å¹´10æœˆ22æ—¥ [GitHub ä¸Šçš„æ›´æ–°](https://github.com/huggingface/blog/blob/main/transformersjs-v3.md)

 æ— 54

*   [![](https://cdn-avatars.huggingface.co/v1/production/uploads/5dd96eb166059660ed1ee413/NQtzmrDdbG0H8qkZvRyGk.jpeg)](/julien-c "julien-c")
*   [![](https://cdn-avatars.huggingface.co/v1/production/uploads/5e3aec01f55e2b62848a5217/PMKS0NNB4MJQlTSFzh918.jpeg)](/lysandre "èŠæ¡‘å¾·çˆ¾")
*   [![](https://cdn-avatars.huggingface.co/v1/production/uploads/1642182289584-5e863990b6845d56ef3d4fb9.jpeg)](/dayanruben "è¾¾æ‰¬é²æœ¬")
*   [![](https://cdn-avatars.huggingface.co/v1/production/uploads/1594214747713-5e9ecfc04957053f60648a3e.png)](/lhoestq "æ´›æ–¯ç‰¹å…‹")
*   [![](https://cdn-avatars.huggingface.co/v1/production/uploads/1613511937628-5fb15d1e84389b139cf3b508.jpeg)](/MoritzLaurer "è«é‡Œå…¹Â·åŠ³é›·å°”")
*   [![](https://cdn-avatars.huggingface.co/v1/production/uploads/1673701526502-60098a0f460b9e8842d93363.jpeg)](/rajivmehtapy "æ‹‰å‰å¤«æ¢…èµ«å¡”çš®")
*   + 48

 [![](https://cdn-avatars.huggingface.co/v1/production/uploads/61b253b7ac5ecaae3d1efe0c/hwiQ0uvz3t-L5a-NtBIO6.png) å¸Œè«¾Â· ç´„æ›¸](/Xenova) 

*   [å®‰è£…](#installation "å®‰è£…")
    
*   [WebGPU æ”¯æŒ](#webgpu-support "WebGPU æ”¯æŒ")
    *   [Transformers.js v3 ä¸­çš„ç”¨æ³•](#usage-in-transformersjs-v3 "Transformers.js v3 ä¸­çš„ç”¨æ³•")
        
*   [æ–°çš„é‡åŒ–æ ¼å¼ (dtypes)](#new-quantization-formats-dtypes "æ–°çš„é‡åŒ–æ ¼å¼ (dtypes)")
    *   [åŸºæœ¬ç”¨æ³•](#basic-usage "åŸºæœ¬ç”¨æ³•")
        
    *   [æ¯ä¸ªæ¨¡å—çš„æ•°æ®ç±»å‹](#per-module-dtypes "æ¯ä¸ªæ¨¡å—çš„æ•°æ®ç±»å‹")
        
*   [120 ç§æ”¯æŒæ¶æ„](#120-supported-architectures "120 ç§æ”¯æŒæ¶æ„")
    
*   [ç¤ºä¾‹é¡¹ç›®å’Œæ¨¡æ¿](#example-projects-and-templates "ç¤ºä¾‹é¡¹ç›®å’Œæ¨¡æ¿")
    
*   [è¶…è¿‡ 1200 ä¸ªé¢„è½¬æ¢æ¨¡å‹](#over-1200-pre-converted-models "è¶…è¿‡ 1200 ä¸ªé¢„è½¬æ¢æ¨¡å‹")
    
*   [Node.js (ESM + CJS)ã€Deno å’Œ Bun å…¼å®¹æ€§](#nodejs-esm--cjs-deno-and-bun-compatibility "Node.js (ESM + CJS)ã€Deno å’Œ Bun å…¼å®¹æ€§")
    
*   [NPM å’Œ GitHub ä¸Šçš„æ–°ä¸»é¡µ](#a-new-home-on-npm-and-github "NPM å’Œ GitHub ä¸Šçš„æ–°ä¸»é¡µ")
    

ç»è¿‡ä¸€å¹´å¤šçš„å¼€å‘ï¼Œæˆ‘ä»¬å¾ˆé«˜å…´åœ°å®£å¸ƒå‘å¸ƒğŸ¤—Transformers.js v3ï¼

äº®ç‚¹åŒ…æ‹¬ï¼š

*   [WebGPUæ”¯æŒï¼ˆæ¯”WASMå¿«100å€ï¼ï¼‰](#webgpu-support)
*   [æ–°çš„é‡åŒ–æ ¼å¼ (dtypes)](#new-quantization-formats-dtypes)
*   [æ”¯æŒ 120 ç§æ¶æ„](#120-supported-architectures)
*   [25 ä¸ªæ–°çš„ç¤ºä¾‹é¡¹ç›®å’Œæ¨¡æ¿](#example-projects-and-templates)
*   [Hugging Face Hub ä¸Šæœ‰è¶…è¿‡ 1200 ä¸ªé¢„è½¬æ¢æ¨¡å‹](#over-1200-pre-converted-models)
*   [Node.js (ESM + CJS)ã€Deno å’Œ Bun å…¼å®¹æ€§](#nodejs-esm--cjs-deno-and-bun-compatibility)
*   [GitHub å’Œ NPM ä¸Šçš„æ–°ä¸»é¡µ](#a-new-home-on-npm-and-github)

[](#installation)å®‰è£…
-------------------

[æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼ä» NPM](https://www.npmjs.com/package/@huggingface/transformers)å®‰è£… Transformers.js v3 ï¼š

```
npmæˆ‘ @huggingface/transformers
```

ç„¶åï¼Œä½¿ç”¨

```
ä»â€œ @huggingface /transformersâ€å¯¼å…¥{ pipeline } ï¼›
```

æˆ–è€…é€šè¿‡ CDN

```
ä»â€œhttps://cdn.jsdelivr.net/npm/@huggingface /transformers@3.0.0 â€å¯¼å…¥{ pipeline } ï¼›
```

æ¬²äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹[æ–‡æ¡£](https://hf.co/docs/transformers.js)ã€‚

[](#webgpu-support)WebGPU æ”¯æŒ
----------------------------

WebGPU æ˜¯ç”¨äºåŠ é€Ÿå›¾å½¢å’Œè®¡ç®—çš„å…¨æ–° Web æ ‡å‡†ã€‚è¯¥[API](https://developer.mozilla.org/en-US/docs/Web/API/WebGPU_API)ä½¿ Web å¼€å‘äººå‘˜èƒ½å¤Ÿä½¿ç”¨åº•å±‚ç³»ç»Ÿçš„ GPU ç›´æ¥åœ¨æµè§ˆå™¨ä¸­æ‰§è¡Œé«˜æ€§èƒ½è®¡ç®—ã€‚WebGPU æ˜¯[WebGL](https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API)çš„åç»§è€…ï¼Œå¯æä¾›æ˜¾ç€æ›´å¥½çš„æ€§èƒ½ï¼Œå› ä¸ºå®ƒå…è®¸ä¸ç°ä»£ GPU è¿›è¡Œæ›´ç›´æ¥çš„äº¤äº’ã€‚æœ€åï¼Œå®ƒæ”¯æŒé€šç”¨ GPU è®¡ç®—ï¼Œè¿™ä¸ªåè®®éå¸¸é€‚åˆæœºå™¨å­¦ä¹ ï¼

> 2024 å¹´ 10 æœˆï¼Œå…¨çƒ WebGPU æ”¯æŒç‡çº¦ä¸º 70%ï¼ˆæ ¹æ®[caniuse.com](https://caniuse.com/webgpu)ï¼‰ï¼Œè¿™æ„å‘³ç€æŸäº›ç”¨æˆ·å¯èƒ½æ— æ³•ä½¿ç”¨è¯¥ APIã€‚
> 
> å¦‚æœä»¥ä¸‹æ¼”ç¤ºåœ¨æ‚¨çš„æµè§ˆå™¨ä¸­æ— æ•ˆï¼Œæ‚¨å¯èƒ½éœ€è¦ä½¿ç”¨åŠŸèƒ½æ ‡å¿—å¯ç”¨å®ƒï¼š
> 
> *   Firefoxï¼šå¸¦æœ‰`dom.webgpu.enabled`æ ‡è®°ï¼ˆå‚è§[æ­¤å¤„](https://developer.mozilla.org/en-US/docs/Mozilla/Firefox/Experimental_features#:~:text=tested%20by%20Firefox.-,WebGPU%20API,-The%20WebGPU%20API)ï¼‰ã€‚
> *   Safariï¼šå¸¦æœ‰`WebGPU`åŠŸèƒ½æ ‡å¿—ï¼ˆå‚è§[æ­¤å¤„](https://webkit.org/blog/14879/webgpu-now-available-for-testing-in-safari-technology-preview/)ï¼‰ã€‚
> *   æ—§ç‰ˆ Chromium æµè§ˆå™¨ï¼ˆåœ¨ Windowsã€macOSã€Linux ä¸Šï¼‰ï¼šå¸¦æœ‰`enable-unsafe-webgpu`æ ‡å¿—ï¼ˆå‚è§[æ­¤å¤„](https://developer.chrome.com/docs/web-platform/webgpu/troubleshooting-tips)ï¼‰ã€‚

### [](#usage-in-transformersjs-v3)Transformers.js v3 ä¸­çš„ç”¨æ³•

æ„Ÿè°¢æˆ‘ä»¬ä¸[ONNX Runtime Web çš„](https://www.npmjs.com/package/onnxruntime-web)åˆä½œï¼Œå¯ç”¨ WebGPU åŠ é€Ÿå°±åƒ`device: 'webgpu'`åœ¨åŠ è½½æ¨¡å‹æ—¶è¿›è¡Œè®¾ç½®ä¸€æ ·ç®€å•ã€‚è®©æˆ‘ä»¬çœ‹ä¸€äº›ç¤ºä¾‹ï¼

**ç¤ºä¾‹ï¼š**åœ¨WebGPUä¸Šè®¡ç®—æ–‡æœ¬åµŒå…¥ï¼ˆ[æ¼”ç¤º](https://v2.scrimba.com/s06a2smeej)ï¼‰

```
ä» â€œ@huggingface/transformersâ€å¯¼å…¥{pipeline} ï¼›

// åˆ›å»ºç‰¹å¾æå–ç®¡é“
const extractor = await pipeline(
   "feature-extraction" ,
   "mixedbread-ai/mxbai-embed-xsmall-v1" ,
  {è®¾å¤‡ï¼šâ€œwebgpuâ€ }ï¼Œ
ï¼ˆè‹±æ–‡ï¼‰ï¼š

// è®¡ç®—åµŒå…¥
const texts = [ "Hello world!" , "This is an example sentence." ];
 const embeddings = await extractor(texts, { pooling : "mean" , normalize : true });
 console .log(embeddings.tolist());
 // [ 
// [-0.016986183822155, 0.03228696808218956, -0.0013630966423079371, ... ], 
// [0.09050482511520386, 0.07207386940717697, 0.05762749910354614, ... ], 
// ]
```

**è¯‘æ–‡ï¼š**åœ¨ WebGPU ä¸Šä½¿ç”¨ OpenAI è€³è¯­æ‰§è¡Œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆ[æ¼”è®²](https://v2.scrimba.com/s0oi76h82g)ï¼‰

```
ä» â€œ@huggingface/transformersâ€å¯¼å…¥{pipeline} ï¼›

// åˆ›å»ºè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ç®¡é“
const transcriber = await pipeline(
   "automatic-speech-recognition" ,
   "onnx-community/whisper-tiny.en" ,
  {è®¾å¤‡ï¼šâ€œwebgpuâ€ }ï¼Œ
ï¼ˆè‹±æ–‡ï¼‰ï¼š

// ä» URL è½¬å½•éŸ³é¢‘
const url = "https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/jfk.wav" ;
 const output = await transcriber(url);
 console .log(output);
 // { text: 'æ‰€ä»¥æˆ‘çš„ç¾å›½åŒèƒä»¬ï¼Œä¸è¦é—®ä½ çš„å›½å®¶èƒ½ä¸ºä½ åšä»€ä¹ˆï¼Œè€Œè¦é—®ä½ èƒ½ä¸ºä½ çš„å›½å®¶åšä»€ä¹ˆã€‚' }
```

**ç¤ºä¾‹ï¼š**åœ¨ WebGPU ä¸Šä½¿ç”¨ MobileNetV4 æ‰§è¡Œå›¾åƒåˆ†ç±»ï¼ˆ[æ¼”ç¤º](https://v2.scrimba.com/s0fv2uab1t)ï¼‰

```
ä» â€œ@huggingface/transformersâ€å¯¼å…¥{pipeline} ï¼›

// åˆ›å»ºå›¾åƒåˆ†ç±»ç®¡é“
const classifier = await pipeline(
   "image-classification" ,
   "onnx-community/mobilenetv4_conv_small.e2400_r224_in1k" ,
  {è®¾å¤‡ï¼šâ€œwebgpuâ€ }ï¼Œ
ï¼ˆè‹±æ–‡ï¼‰ï¼š

// é€šè¿‡ URL å¯¹å›¾åƒè¿›è¡Œåˆ†ç±»
const url = "https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/tiger.jpg" ;
 const output = await classifier(url);
 console.log (output);
 // [ 
// { æ ‡ç­¾ï¼š'è€è™ï¼ŒPanthera tigris'ï¼Œå¾—åˆ†ï¼š0.6149784922599792 }, 
// { æ ‡ç­¾ï¼š'è™çŒ«'ï¼Œå¾—åˆ†ï¼š0.30281734466552734 }, 
// { æ ‡ç­¾ï¼š'è™æ–‘çŒ«ï¼Œè™æ–‘çŒ«'ï¼Œå¾—åˆ†ï¼š0.0019135422771796584 }, 
// { æ ‡ç­¾ï¼š'å±±çŒ«ï¼Œç¾æ´²å±±çŒ«'ï¼Œå¾—åˆ†ï¼š0.0012161266058683395 }, 
// { æ ‡ç­¾ï¼š'åŸƒåŠçŒ«'ï¼Œå¾—åˆ†ï¼š0.0011465961579233408 } 
// ]
```

[](#new-quantization-formats-dtypes)æ–°çš„é‡åŒ–æ ¼å¼ (dtypes)
---------------------------------------------------

åœ¨ Transformers.js v3 ä¹‹å‰ï¼Œæˆ‘ä»¬é€šè¿‡åˆ†åˆ«è®¾ç½®ä¸ºæˆ–`quantized`æ¥æŒ‡å®šæ˜¯å¦ä½¿ç”¨æ¨¡å‹çš„é‡åŒ– (q8) æˆ–å…¨ç²¾åº¦ (fp32) å˜ä½“ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬æ·»åŠ äº†ä½¿ç”¨å‚æ•°ä»æ›´å¤§åˆ—è¡¨ä¸­è¿›è¡Œé€‰æ‹©çš„åŠŸèƒ½ã€‚`quantized``true``false``dtype`

å¯ç”¨é‡åŒ–çš„åˆ—è¡¨å–å†³äºæ¨¡å‹ï¼Œä½†ä¸€äº›å¸¸è§çš„é‡åŒ–æ˜¯ï¼šå…¨ç²¾åº¦ï¼ˆï¼‰`"fp32"`ã€åŠç²¾åº¦ï¼ˆ`"fp16"`ï¼‰ã€8 ä½ï¼ˆ`"q8"`ã€ã€`"int8"`ï¼‰`"uint8"`å’Œ 4 ä½ï¼ˆ`"q4"`ã€ã€ï¼‰ã€‚`"bnb4"``"q4f16"`

 ![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/transformersjs-v3/dtypes-dark.jpg) [ï¼ˆä¾‹å¦‚ï¼Œmixedbread-ai/mxbai-embed-xsmall-v1ï¼‰](https://huggingface.co/mixedbread-ai/mxbai-embed-xsmall-v1/tree/main/onnx)

### [](#basic-usage)åŸºæœ¬ç”¨æ³•

**ç¤ºä¾‹ï¼š**ä»¥ 4 ä½é‡åŒ–è¿è¡Œ Qwen2.5-0.5B-Instructï¼ˆ[æ¼”ç¤º](https://v2.scrimba.com/s0dlcpv0ci)ï¼‰

```
import { pipeline } from "@huggingface/transformers";

// Create a text generation pipeline
const generator = await pipeline(
  "text-generation",
  "onnx-community/Qwen2.5-0.5B-Instruct",
  { dtype: "q4", device: "webgpu" },
);

// Define the list of messages
const messages = [
  { role: "system", content: "You are a helpful assistant." },
  { role: "user", content: "Tell me a funny joke." },
];

// Generate a response
const output = await generator(messages, { max_new_tokens: 128 });
console.log(output[0].generated_text.at(-1).content);
```

### [](#per-module-dtypes)æ¯ä¸ªæ¨¡å—çš„æ•°æ®ç±»å‹

ä¸€äº›ç¼–ç å™¨ - è§£ç å™¨æ¨¡å‹ï¼ˆå¦‚ Whisper æˆ– Florence-2ï¼‰å¯¹é‡åŒ–è®¾ç½®æä¸ºæ•æ„Ÿï¼šå°¤å…¶æ˜¯ç¼–ç å™¨çš„é‡åŒ–è®¾ç½®ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ·»åŠ äº†é€‰æ‹©æ¯ä¸ªæ¨¡å— dtypes çš„åŠŸèƒ½ï¼Œè¿™å¯ä»¥é€šè¿‡æä¾›ä»æ¨¡å—åç§°åˆ° dtype çš„æ˜ å°„æ¥å®ç°ã€‚

**ç¤ºä¾‹ï¼š**åœ¨ WebGPU ä¸Šè¿è¡Œ Florence-2ï¼ˆ[æ¼”ç¤º](https://v2.scrimba.com/s0pdm485fo)ï¼‰

```
import { Florence2ForConditionalGeneration } from "@huggingface/transformers";

const model = await Florence2ForConditionalGeneration.from_pretrained(
  "onnx-community/Florence-2-base-ft",
  {
    dtype: {
      embed_tokens: "fp16",
      vision_encoder: "fp16",
      encoder_model: "q4",
      decoder_model_merged: "q4",
    },
    device: "webgpu",
  },
);
```

![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/transformersjs-v3/florence-2-webgpu.gif)

æŸ¥çœ‹å®Œæ•´ä»£ç ç¤ºä¾‹

```
import {
  Florence2ForConditionalGeneration,
  AutoProcessor,
  AutoTokenizer,
  RawImage,
} from "@huggingface/transformers";

// Load model, processor, and tokenizer
const model_id = "onnx-community/Florence-2-base-ft";
const model = await Florence2ForConditionalGeneration.from_pretrained(
  model_id,
  {
    dtype: {
      embed_tokens: "fp16",
      vision_encoder: "fp16",
      encoder_model: "q4",
      decoder_model_merged: "q4",
    },
    device: "webgpu",
  },
);
const processor = await AutoProcessor.from_pretrained(model_id);
const tokenizer = await AutoTokenizer.from_pretrained(model_id);

// Load image and prepare vision inputs
const url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg";
const image = await RawImage.fromURL(url);
const vision_inputs = await processor(image);

// Specify task and prepare text inputs
const task = "<MORE_DETAILED_CAPTION>";
const prompts = processor.construct_prompts(task);
const text_inputs = tokenizer(prompts);

// Generate text
const generated_ids = await model.generate({
  ...text_inputs,
  ...vision_inputs,
  max_new_tokens: 100,
});

// Decode generated text
const generated_text = tokenizer.batch_decode(generated_ids, {
  skip_special_tokens: false,
})[0];

// Post-process the generated text
const result = processor.post_process_generation(
  generated_text,
  task,
  image.size,
);
console.log(result);
// { '<MORE_DETAILED_CAPTION>': 'A green car is parked in front of a tan building. The building has a brown door and two brown windows. The car is a two door and the door is closed. The green car has black tires.' }
```

[](#120-supported-architectures)120 ç§å—æ”¯æŒçš„æ¶æ„
-------------------------------------------

æ­¤ç‰ˆæœ¬å°†æ”¯æŒçš„æ¶æ„æ€»æ•°å¢åŠ åˆ° 120 ä¸ªï¼ˆæŸ¥çœ‹[å®Œæ•´åˆ—è¡¨](https://huggingface.co/docs/transformers.js/index#models)ï¼‰ï¼Œæ¶µç›–äº†å¹¿æ³›çš„è¾“å…¥æ¨¡å¼å’Œä»»åŠ¡ã€‚å€¼å¾—æ³¨æ„çš„æ–°åç§°åŒ…æ‹¬ï¼šPhi-3ã€Gemma & Gemma 2ã€LLaVaã€Moondreamã€Florence-2ã€MusicGenã€Sapiensã€Depth Proã€PyAnnote å’Œ RT-DETRã€‚

![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/transformersjs-v3/architectures.png)

æ–°æ¬¾è½¦å‹ä¸€è§ˆ

1.  **[Cohere](https://huggingface.co/docs/transformers/main/model_doc/cohere)**ï¼ˆæ¥è‡ª Cohereï¼‰å‘å¸ƒäº†è®ºæ–‡[ã€ŠCommand-Rï¼šCohere çš„ç”Ÿäº§è§„æ¨¡æ£€ç´¢å¢å¼ºç”Ÿæˆã€‹](https://txt.cohere.com/command-r/)ã€‚
2.  **[Decision Transformer](https://huggingface.co/docs/transformers/model_doc/decision_transformer)**ï¼ˆæ¥è‡ªä¼¯å…‹åˆ© / Facebook/Googleï¼‰ä¸è®ºæ–‡[ã€Šå†³ç­–å˜å‹å™¨ï¼šé€šè¿‡åºåˆ—å»ºæ¨¡è¿›è¡Œå¼ºåŒ–å­¦ä¹ ã€‹](https://arxiv.org/abs/2106.01345)ä¸€èµ·å‘å¸ƒï¼Œè®ºæ–‡ä½œè€…æ˜¯ Lili Chenã€Kevin Luã€Aravind Rajeswaranã€Kimin Leeã€Aditya Groverã€Michael Laskinã€Pieter Abbeelã€Aravind Srinivas å’Œ Igor Mordatchã€‚
3.  **Depth Pro**ï¼ˆæ¥è‡ª Appleï¼‰å‘å¸ƒäº†è®ºæ–‡ã€Š[Depth Proï¼šä¸åˆ°ä¸€ç§’çš„æ¸…æ™°å•ç›®åº¦é‡æ·±åº¦ã€‹ï¼Œ](https://arxiv.org/abs/2410.02073)ä½œè€…æ˜¯ Aleksei Bochkovskiiã€AmaÃ«l Delaunoyã€Hugo Germainã€Marcel Santosã€Yichao Zhouã€Stephan R. Richter å’Œ Vladlen Koltunã€‚
4.  **Florence2**ï¼ˆæ¥è‡ªå¾®è½¯ï¼‰ä¸è®ºæ–‡[ã€ŠFlorence-2ï¼šä¸ºå„ç§è§†è§‰ä»»åŠ¡æä¾›ç»Ÿä¸€çš„è¡¨ç¤ºã€‹ä¸€åŒ](https://arxiv.org/abs/2311.06242)å‘å¸ƒï¼Œè®ºæ–‡ä½œè€…ä¸º Bin Xiaoã€Haiping Wuã€Weijian Xuã€Xiyang Daiã€Houdong Huã€Yumao Luã€Michael Zengã€Ce Liu å’Œ Lu Yuanã€‚
5.  **[Gemma](https://huggingface.co/docs/transformers/main/model_doc/gemma)**ï¼ˆæ¥è‡ª Googleï¼‰å‘å¸ƒäº†è®ºæ–‡[ã€ŠGemmaï¼šåŸºäº Gemini æŠ€æœ¯å’Œ](https://blog.google/technology/developers/gemma-open-models/) Gemma Google å›¢é˜Ÿç ”ç©¶çš„å¼€æ”¾æ¨¡å‹ã€‹ã€‚
6.  **[Gemma2](https://huggingface.co/docs/transformers/main/model_doc/gemma2)** [ï¼ˆæ¥è‡ª Googleï¼‰å‘å¸ƒäº† Gemma2ï¼šåŸºäº Gemini æŠ€æœ¯å’Œç ”ç©¶çš„å¼€æ”¾æ¨¡å‹](https://blog.google/technology/developers/google-gemma-2/)è®ºæ–‡ã€‚
7.  **[Granite](https://huggingface.co/docs/transformers/main/model_doc/granite)**ï¼ˆæ¥è‡ª IBMï¼‰å‘å¸ƒäº†è®ºæ–‡ã€Š [Power Schedulerï¼šä¸æ‰¹æ¬¡å¤§å°å’Œä»¤ç‰Œæ•°é‡æ— å…³çš„å­¦ä¹ ç‡è°ƒåº¦ç¨‹åºã€‹ï¼Œ](https://arxiv.org/abs/2408.13359)ä½œè€…ä¸º Yikang Shenã€Matthew Stalloneã€Mayank Mishraã€Gaoyuan Zhangã€Shawn Tanã€Aditya Prasadã€Adriana Meza Soriaã€David D. Cox å’Œ Rameswar Pandaã€‚
8.  **[GroupViT](https://huggingface.co/docs/transformers/model_doc/groupvit)** (from UCSD, NVIDIA) released with the paper [GroupViT: Semantic Segmentation Emerges from Text Supervision](https://arxiv.org/abs/2202.11094) by Jiarui Xu, Shalini De Mello, Sifei Liu, Wonmin Byeon, Thomas Breuel, Jan Kautz, Xiaolong Wang.
9.  **[Hiera](https://huggingface.co/docs/transformers/model_doc/hiera)** (from Meta) released with the paper [Hiera: A Hierarchical Vision Transformer without the Bells-and-Whistles](https://arxiv.org/pdf/2306.00989) by Chaitanya Ryali, Yuan-Ting Hu, Daniel Bolya, Chen Wei, Haoqi Fan, Po-Yao Huang, Vaibhav Aggarwal, Arkabandhu Chowdhury, Omid Poursaeed, Judy Hoffman, Jitendra Malik, Yanghao Li, Christoph Feichtenhofer.
10.  **JAIS** (from Core42) released with the paper [Jais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open Generative Large Language Models](https://arxiv.org/pdf/2308.16149) by Neha Sengupta, Sunil Kumar Sahu, Bokang Jia, Satheesh Katipomu, Haonan Li, Fajri Koto, William Marshall, Gurpreet Gosal, Cynthia Liu, Zhiming Chen, Osama Mohammed Afzal, Samta Kamboj, Onkar Pandit, Rahul Pal, Lalit Pradhan, Zain Muhammad Mujahid, Massa Baali, Xudong Han, Sondos Mahmoud Bsharat, Alham Fikri Aji, Zhiqiang Shen, Zhengzhong Liu, Natalia Vassilieva, Joel Hestness, Andy Hock, Andrew Feldman, Jonathan Lee, Andrew Jackson, Hector Xuguang Ren, Preslav Nakov, Timothy Baldwin, Eric Xing.
11.  **[LLaVa](https://huggingface.co/docs/transformers/model_doc/llava)** (from Microsoft Research & University of Wisconsin-Madison) released with the paper [Visual Instruction Tuning](https://arxiv.org/abs/2304.08485) by Haotian Liu, Chunyuan Li, Yuheng Li and Yong Jae Lee.
12.  **[MaskFormer](https://huggingface.co/docs/transformers/model_doc/maskformer)** (from Meta and UIUC) released with the paper [Per-Pixel Classification is Not All You Need for Semantic Segmentation](https://arxiv.org/abs/2107.06278) by Bowen Cheng, Alexander G. Schwing, Alexander Kirillov.
13.  **[MusicGen](https://huggingface.co/docs/transformers/model_doc/musicgen)** (from Meta) released with the paper [Simple and Controllable Music Generation](https://arxiv.org/abs/2306.05284) by Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi and Alexandre DÃ©fossez.
14.  **MobileCLIP** (from Apple) released with the paper [MobileCLIP: Fast Image-Text Models through Multi-Modal Reinforced Training](https://arxiv.org/abs/2311.17049) by Pavan Kumar Anasosalu Vasu, Hadi Pouransari, Fartash Faghri, Raviteja Vemulapalli, Oncel Tuzel.
15.  **[MobileNetV1](https://huggingface.co/docs/transformers/model_doc/mobilenet_v1)** (from Google Inc.) released with the paper [MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/abs/1704.04861) by Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam.
16.  **[MobileNetV2](https://huggingface.co/docs/transformers/model_doc/mobilenet_v2)** (from Google Inc.) released with the paper [MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://arxiv.org/abs/1801.04381) by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen.
17.  **MobileNetV3** (from Google Inc.) released with the paper [Searching for MobileNetV3](https://arxiv.org/abs/1905.02244) by Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo Chen, Mingxing Tan, Weijun Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan, Quoc V. Le, Hartwig Adam.
18.  **MobileNetV4** (from Google Inc.) released with the paper [MobileNetV4 - Universal Models for the Mobile Ecosystem](https://arxiv.org/abs/2404.10518) by Danfeng Qin, Chas Leichner, Manolis Delakis, Marco Fornoni, Shixin Luo, Fan Yang, Weijun Wang, Colby Banbury, Chengxi Ye, Berkin Akin, Vaibhav Aggarwal, Tenghui Zhu, Daniele Moro, Andrew Howard.
19.  **Moondream1** released in the repository [moondream](https://github.com/vikhyat/moondream) by vikhyat.
20.  **OpenELM** (from Apple) released with the paper [OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework](https://arxiv.org/abs/2404.14619) by Sachin Mehta, Mohammad Hossein Sekhavat, Qingqing Cao, Maxwell Horton, Yanzi Jin, Chenfan Sun, Iman Mirzadeh, Mahyar Najibi, Dmitry Belenko, Peter Zatloukal, Mohammad Rastegari.
21.  **[Phi3](https://huggingface.co/docs/transformers/main/model_doc/phi3)** (from Microsoft) released with the paper [Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone](https://arxiv.org/abs/2404.14219) by Marah Abdin, Sam Ade Jacobs, Ammar Ahmad Awan, Jyoti Aneja, Ahmed Awadallah, Hany Awadalla, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Harkirat Behl, Alon Benhaim, Misha Bilenko, Johan Bjorck, SÃ©bastien Bubeck, Martin Cai, Caio CÃ©sar Teodoro Mendes, Weizhu Chen, Vishrav Chaudhary, Parul Chopra, Allie Del Giorno, Gustavo de Rosa, Matthew Dixon, Ronen Eldan, Dan Iter, Amit Garg, Abhishek Goswami, Suriya Gunasekar, Emman Haider, Junheng Hao, Russell J. Hewett, Jamie Huynh, Mojan Javaheripi, Xin Jin, Piero Kauffmann, Nikos Karampatziakis, Dongwoo Kim, Mahoud Khademi, Lev Kurilenko, James R. Lee, Yin Tat Lee, Yuanzhi Li, Chen Liang, Weishung Liu, Eric Lin, Zeqi Lin, Piyush Madan, Arindam Mitra, Hardik Modi, Anh Nguyen, Brandon Norick, Barun Patra, Daniel Perez-Becker, Thomas Portet, Reid Pryzant, Heyang Qin, Marko Radmilac, Corby Rosset, Sambudha Roy, Olatunji Ruwase, Olli Saarikivi, Amin Saied, Adil Salim, Michael Santacroce, Shital Shah, Ning Shang, Hiteshi Sharma, Xia Song, Masahiro Tanaka, Xin Wang, Rachel Ward, Guanhua Wang, Philipp Witte, Michael Wyatt, Can Xu, Jiahang Xu, Sonali Yadav, Fan Yang, Ziyi Yang, Donghan Yu, Chengruidong Zhang, Cyril Zhang, Jianwen Zhang, Li Lyna Zhang, Yi Zhang, Yue Zhang, Yunan Zhang, Xiren Zhou.
22.  **[PVT](https://huggingface.co/docs/transformers/main/model_doc/pvt)** (from Nanjing University, The University of Hong Kong etc.) released with the paper [Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions](https://arxiv.org/pdf/2102.12122.pdf) by Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong Lu, Ping Luo, Ling Shao.
23.  **PyAnnote** released in the repository [pyannote/pyannote-audio](https://github.com/pyannote/pyannote-audio) by HervÃ© Bredin.
24.  **[RT-DETR](https://huggingface.co/docs/transformers/model_doc/rt_detr)** ï¼ˆæ¥è‡ªç™¾åº¦ï¼‰ï¼Œä¸èµµä¸€å®‰ã€å•æ–‡å®‡ã€å¾å°šäº®ã€é­é‡‘æ›¼ã€ç‹ç®¡ä¸­ã€å…šé’é’ã€åˆ˜æ¯…ã€é™ˆæ°çš„è®ºæ–‡[ã€ŠDETRs Beat YOLOs on Real-time ObjectDetectionã€‹ä¸€èµ·å‘å¸ƒã€‚](https://arxiv.org/abs/2304.08069)
25.  **Sapiens**ï¼ˆæ¥è‡ª Meta AIï¼‰ä¸è®ºæ–‡[ã€ŠSapiensï¼šäººç±»è§†è§‰æ¨¡å‹åŸºç¡€ã€‹](https://arxiv.org/pdf/2408.12569)ä¸€èµ·å‘å¸ƒï¼Œè®ºæ–‡ä½œè€…æ˜¯ Rawal Khirodkarã€Timur Bagautdinovã€Julieta Martinezã€Su Zhaoenã€Austin Jamesã€Peter Selednikã€Stuart Anderson å’Œ Shunsuke Saitoã€‚
26.  **[ViTMAE](https://huggingface.co/docs/transformers/model_doc/vit_mae)** ï¼ˆæ¥è‡ª Meta AIï¼‰ä¸ Kaiming Heã€Xinlei Chenã€Saining Xieã€Yanghao Liã€Piotr DollÃ¡r å’Œ Ross Girshick æ’°å†™çš„è®ºæ–‡[ã€ŠMasked Autoencoders Are Scalable Vision Learnersã€‹ä¸€èµ·å‘å¸ƒã€‚](https://arxiv.org/abs/2111.06377)
27.  **[ViTMSN](https://huggingface.co/docs/transformers/model_doc/vit_msn)** ï¼ˆæ¥è‡ª Meta AIï¼‰ä¸ Mahmoud Assranã€Mathilde Caronã€Ishan Misraã€Piotr Bojanowskiã€Florian Bordesã€Pascal Vincentã€Armand Joulinã€Michael Rabbat å’Œ Nicolas Ballas æ’°å†™çš„è®ºæ–‡[ã€Šç”¨äºæ ‡ç­¾é«˜æ•ˆå­¦ä¹ çš„è’™é¢æš¹ç½—ç½‘ç»œã€‹ä¸€èµ·å‘å¸ƒã€‚](https://arxiv.org/abs/2204.07141)

[](#example-projects-and-templates)ç¤ºä¾‹é¡¹ç›®å’Œæ¨¡æ¿
------------------------------------------

ä½œä¸ºå‘å¸ƒçš„ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å‘å¸ƒäº† 25 ä¸ªæ–°çš„ç¤ºä¾‹é¡¹ç›®å’Œæ¨¡æ¿ï¼Œä¸»è¦ä¾§é‡äºå±•ç¤º WebGPU æ”¯æŒï¼å…¶ä¸­åŒ…æ‹¬ [Phi-3.5 WebGPU](https://github.com/huggingface/transformers.js-examples/tree/main/phi-3.5-webgpu) å’Œ [Whisper WebGPU](https://github.com/xenova/whisper-web/tree/experimental-webgpu) ç­‰æ¼”ç¤ºï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚

> æˆ‘ä»¬æ­£åœ¨å°†æ‰€æœ‰ç¤ºä¾‹é¡¹ç›®å’Œæ¼”ç¤ºç§»è‡³ [https://github.com/huggingface/transformers.js-examples](https://github.com/huggingface/transformers.js-examples)ï¼Œæ•¬è¯·å…³æ³¨æœ€æ–°æ›´æ–°ï¼

<table><thead><tr><th align="center"><img class="" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/transformersjs-v3/phi-3.5-webgpu.gif" style="width: auto;"></th><th align="center"><img class="" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/transformersjs-v3/whisper-turbo-webgpu.gif" style="width: auto;"></th></tr></thead></table>

[](#over-1200-pre-converted-models)è¶…è¿‡ 1200 ä¸ªé¢„è½¬æ¢æ¨¡å‹
-------------------------------------------------

ä»Šå¤©å‘å¸ƒï¼Œç¤¾åŒºå·²å°†è¶…è¿‡ 1200 ä¸ªæ¨¡å‹è½¬æ¢ä¸ºä¸ Transformers.js å…¼å®¹ï¼æ‚¨å¯ä»¥[åœ¨æ­¤å¤„](https://hf.co/models?library=transformers.js)æ‰¾åˆ°å¯ç”¨æ¨¡å‹çš„å®Œæ•´åˆ—è¡¨ã€‚

å¦‚æœæ‚¨æƒ³è½¬æ¢è‡ªå·±çš„æ¨¡å‹æˆ–è¿›è¡Œä¸€äº›é…ç½®ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æˆ‘ä»¬çš„[è½¬æ¢è„šæœ¬](https://github.com/huggingface/transformers.js/blob/main/scripts/convert.py)ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```
python  -m è„šæœ¬.convert  --quantize  --model_id <æ¨¡å‹åç§°æˆ–è·¯å¾„>
```

å°†ç”Ÿæˆçš„æ–‡ä»¶ä¸Šä¼ åˆ°Huging Face Hubåï¼Œè¯·è®°ä½æ·»åŠ æ ‡ç­¾ï¼Œ`transformers.js`ä»¥ä¾¿å…¶ä»–äººå¯ä»¥è½»æ¾æ‰¾åˆ°å¹¶ä½¿ç”¨æ‚¨çš„æ¨¡å‹ï¼

 ![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/transformersjs-v3/models-dark.jpg) 

[](#nodejs-esm--cjs-deno-and-bun-compatibility)Node.js (ESM + CJS)ã€Deno å’Œ Bun å…¼å®¹æ€§
---------------------------------------------------------------------------------

Transformers.js v3 ç°åœ¨ä¸æ¸…æ™°æœ€æµè¡Œçš„æœåŠ¡å™¨ç«¯ JavaScript è¿è¡Œæ—¶å…¼å®¹ï¼š

<table><thead><tr><th>è„šæœ¬</th><th>æè¿°</th><th>ç¤ºä¾‹</th></tr></thead><tbody><tr><td><a href="https://nodejs.org/">Node.js</a></td><td>åŸºäº Chrome V8 æ„å»ºçš„å¹¿æ³›ä½¿ç”¨çš„ JavaScript è¿è¡Œæ—¶ã€‚å®ƒæ‹¥æœ‰åºå¤§çš„ç”Ÿæ€ç³»ç»Ÿå¹¶æ”¯æŒå„ç§åº“å’Œæ¡†æ¶ã€‚</td><td><a href="https://github.com/huggingface/transformers.js-examples/tree/main/node-esm">ESM ç¤ºä¾‹</a>/ <a href="https://github.com/huggingface/transformers.js-examples/tree/main/node-cjs">CJS ç¤ºä¾‹</a></td></tr><tr><td><a href="https://deno.com/">å¾·è«¾</a></td><td>JavaScript å’Œ TypeScript çš„ç°ä»£è¿è¡Œæ—¶ï¼Œé»˜è®¤æƒ…å†µä¸‹æ˜¯å®‰å…¨çš„ã€‚å®ƒä½¿ç”¨ ES æ¨¡å—ï¼Œç”šè‡³å…·æœ‰å®éªŒæ€§çš„ WebGPU æ”¯æŒã€‚</td><td><a href="https://github.com/huggingface/transformers.js-examples/tree/main/deno-embed">Deno ç¤ºä¾‹</a></td></tr><tr><td><a href="https://bun.sh/">åŒ…å­</a></td><td>é’ˆå¯¹æ€§èƒ½è¿›è¡Œäº†å¿«é€ŸJavaScriptè¿è¡Œæ—¶çš„ä¼˜åŒ–ã€‚å®ƒå…·æœ‰å†…ç½®çš„æ†ç»‘å™¨ã€è½¬è¯‘å™¨å’ŒåŒ…ç®¡ç†å™¨ã€‚</td><td><a href="https://github.com/huggingface/transformers.js-examples/tree/main/bun">é¢åŒ…ç¤ºä¾‹</a></td></tr></tbody></table>

[](#a-new-home-on-npm-and-github)NPM å’Œ GitHub ä¸Šçš„æ–°ä¸»é¡µ
---------------------------------------------------

æœ€åï¼Œæˆ‘ä»¬å¾ˆé«˜å…´åœ°å®£å¸ƒï¼ŒTransformers.js ç°åœ¨å°†åœ¨ NPM ä¸Šä»¥å®˜æ–¹ Hugging Face ç»„ç»‡çš„åç§°å‘å¸ƒï¼ˆè€Œä¸æ˜¯ ç”¨äº v1 å’Œ v2 çš„ï¼‰ã€‚[`@huggingface/transformers`](https://www.npmjs.com/package/@huggingface/transformers)[`@xenova/transformers`](https://www.npmjs.com/package/@xenova/transformers)

æˆ‘ä»¬è½¬å‹å­˜å‚¨åº“è¿ç§»è‡³ GitHub ä¸Šçš„å®˜æ–¹ Hugging Face ç»„ç»‡ ( [https://github.com/huggingface/transformers.js](https://github.com/huggingface/transformers.js) )ï¼Œè¿™å°†æˆä¸ºæˆ‘ä»¬çš„æ–°å®¶ â€” å¿«æ¥æ‰“ä¸ªæ‹›å‘¼å§ï¼æˆ‘ä»¬æœŸå¾…æ”¶åˆ°æ‚¨çš„åé¦ˆã€å›å¤æ‚¨çš„é—®é¢˜å¹¶å®¡æ ¸æ‚¨çš„å…¬å…³ï¼

è¿™æ˜¯ä¸€ä¸ªé‡è¦çš„é‡Œç¨‹ç¢‘ï¼Œæˆ‘ä»¬éå¸¸æ„Ÿè°¢ç¤¾åŒºå¸®åŠ©æˆ‘ä»¬å®ç°è¿™ä¸ªé•¿æœŸç›®æ ‡ï¼å¦‚æœæ²¡æœ‰ä½ ä»¬çš„æ‰€æœ‰æƒï¼Œè¿™ä¸€åˆ‡éƒ½ä¸å¯èƒ½å®ç°â€¦â€¦è°¢è°¢ï¼ğŸ¤—